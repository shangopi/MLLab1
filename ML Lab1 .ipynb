{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0eccdf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas to create DataFrame \n",
    "import pandas as pd \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "  \n",
    "# Make DataFrame of the given data \n",
    "data = pd.read_csv('train.csv')\n",
    "valid = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c66333b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_1        0\n",
      "feature_2        0\n",
      "feature_3        0\n",
      "feature_4        0\n",
      "feature_5        0\n",
      "              ... \n",
      "feature_256      0\n",
      "label_1          0\n",
      "label_2        480\n",
      "label_3          0\n",
      "label_4          0\n",
      "Length: 260, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Checking provided data\n",
    "null_counts = data.isnull().sum()\n",
    "\n",
    "print(null_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8801ee1a",
   "metadata": {},
   "source": [
    "Label 2 only has missing values wheras other columns don't have any missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2dd519",
   "metadata": {},
   "source": [
    "Here we are going to do Principal Component Analysis (PCA). Principal Component Analysis (PCA) is a dimensionality reduction technique used to transform high-dimensional data into a lower-dimensional space while preserving as much of the original data's variance as possible. It's commonly used for feature extraction, data visualization, and noise reduction. PCA identifies the principal components (linear combinations of the original features) that capture the most significant variations in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fc132790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def perform_PCA(x,x_valid,n):   \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit_transform(x)\n",
    "    scaled_x = scaler.transform(x)\n",
    "    scaled_x_valid = scaler.transform(x_valid)\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(scaled_x)\n",
    "    x_pca = pca.transform(scaled_x)\n",
    "    x_pca_valid = pca.transform(scaled_x_valid)\n",
    "    pca_df = pd.DataFrame(data=x_pca)\n",
    "    pca_valid_df = pd.DataFrame(data=x_pca_valid)\n",
    "    return pca_df, pca_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8caa9576",
   "metadata": {},
   "source": [
    "Mutual information (MI) between two random variables is a non-negative value, which measures the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency. The function relies on nonparametric methods based on entropy estimation from k-nearest neighbors distances. Mutual information is calculated between two variables and measures the reduction in uncertainty for one variable given a known value of the other variable. Inshort A quantity called mutual information measures the amount of information one can obtain from one random variable given another. The mutual information between two random variables X and Y can be stated formally as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d165cad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def select_cols_using_mutual_info_regression(x,y,n) :\n",
    "    selected_columns = SelectKBest(mutual_info_regression, k=n)\n",
    "    selected_columns.fit(x, y)\n",
    "    return x.columns[selected_columns.get_support()]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670fc0ec",
   "metadata": {},
   "source": [
    "This function is used to compare the accuracy scores of train and valid data and make adjustments. \n",
    "Here we use KNN model with 7 nearest neighbours.\n",
    "\n",
    "Initially we get accuracy scores for features without feature reduction\n",
    "\n",
    "Then we calclate accuracy scores after feature reduction process.\n",
    "\n",
    "Here x after parameter - > x_train after feature engineering process\n",
    "x_valid_after -> x_valid after feature engineering process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "861e8bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def predict(x,y,x_valid,y_valid,x_after,x_valid_after):\n",
    "    k = 7  # Number of neighbors\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(x, y)\n",
    "    X_test_contiguous = np.ascontiguousarray(x_valid)\n",
    "    y_pred = knn_model.predict(X_test_contiguous)\n",
    "    precision = precision_score(y_valid, y_pred, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred, average='weighted')\n",
    "    print(f\"Before feature extraction, Accuracy : {accuracy_score(y_valid, y_pred):.3f} | Precision : {precision:.3f} | Recall : {recall:.3f}\")\n",
    "    \n",
    "    k = 7  # Number of neighbors\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(x_after, y)\n",
    "    X_test_contiguous = np.ascontiguousarray(x_valid_after)\n",
    "    y_pred = knn_model.predict(X_test_contiguous)\n",
    "    precision = precision_score(y_valid, y_pred, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred, average='weighted')\n",
    "    print(f\"After feature extraction, Accuracy : {accuracy_score(y_valid, y_pred):.3f} | Precision : {precision:.3f} | Recall : {recall:.3f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3a8b8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dependent & Independent features\n",
    "y = data[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "y_valid = valid[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x = data.drop(y, axis=1)\n",
    "x_valid = valid.drop(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40114925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature extraction, Accuracy : 0.987 | Precision : 0.988 | Recall : 0.987\n",
      "After feature extraction, Accuracy : 0.976 | Precision : 0.979 | Recall : 0.976\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_1'],100)\n",
    "pca_x, pca_x_valid = perform_PCA(x[selected_cols],x_valid[selected_cols],40)\n",
    "predict(x,y['label_1'],x_valid,y_valid['label_1'],pca_x,pca_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a05e3caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature extraction, Accuracy : 1.000 | Precision : 1.000 | Recall : 1.000\n",
      "After feature extraction, Accuracy : 1.000 | Precision : 1.000 | Recall : 1.000\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_3'],100)\n",
    "pca_x, pca_x_valid = perform_PCA(x[selected_cols],x_valid[selected_cols],15)\n",
    "predict(x,y['label_3'],x_valid,y_valid['label_3'],pca_x,pca_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "122952d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature extraction, Accuracy : 0.993 | Precision : 0.993 | Recall : 0.993\n",
      "After feature extraction, Accuracy : 0.983 | Precision : 0.983 | Recall : 0.983\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_4'],100)\n",
    "pca_x, pca_x_valid = perform_PCA(x[selected_cols],x_valid[selected_cols],30)\n",
    "predict(x,y['label_4'],x_valid,y_valid['label_4'],pca_x,pca_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb7157f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_2 = data.dropna(subset=['label_2'])\n",
    "valid_label_2 = valid.dropna(subset=['label_2'])\n",
    "y_label_2 = data_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2 = data_label_2.drop(y_label_2, axis=1)\n",
    "y_label_2_valid = valid_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]] \n",
    "x_label_2_valid = valid_label_2.drop(y_label_2_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "621583ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before feature extraction, Accuracy : 0.988 | Precision : 0.988 | Recall : 0.988\n",
      "After feature extraction, Accuracy : 0.973 | Precision : 0.974 | Recall : 0.973\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x_label_2,y_label_2['label_2'],100)\n",
    "pca_x, pca_x_valid = perform_PCA(x_label_2[selected_cols],x_label_2_valid[selected_cols],40)\n",
    "predict(x_label_2,y_label_2['label_2'],x_label_2_valid,y_label_2_valid['label_2'],pca_x,pca_x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69491ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab69ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dependent & Independent features\n",
    "y_test = test[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "x_test = test.drop(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bc0ddf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def test_data_predict(x,y,x_test,x_after,x_test_after,name,feature_no):\n",
    "    k = 7  # Number of neighbors\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(x, y)\n",
    "    X_test_contiguous = np.ascontiguousarray(x_test)\n",
    "    y_pred_before = knn_model.predict(X_test_contiguous)\n",
    "    print(\"Sucessfully predicted labels before feature engineering\")\n",
    "    \n",
    "    k = 7  # Number of neighbors\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_model.fit(x_after, y)\n",
    "    X_test_contiguous = np.ascontiguousarray(x_test_after)\n",
    "    y_pred_after = knn_model.predict(X_test_contiguous)\n",
    "    print(\"Sucessfully predicted labels after feature engineering\")\n",
    "    \n",
    "    result_df = pd.concat([pd.Series(y_pred_before, name='. Predicted labels before feature engineering'), pd.Series(y_pred_after, name='Predicted labels after feature engineering'), pd.Series(feature_no, name='No. of new features'), x_test_after], axis=1)    \n",
    "    output_file_name = \"190199A_\"+name+\".csv\"\n",
    "    result_df.to_csv(output_file_name, index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8642f48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted labels before feature engineering\n",
      "Sucessfully predicted labels after feature engineering\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_1'],100)\n",
    "num_features = 40\n",
    "pca_x, pca_x_test = perform_PCA(x[selected_cols],x_test[selected_cols],num_features)\n",
    "pca_x_test.columns = ['New feature ' + str(i) for i in range(1, num_features + 1)]\n",
    "\n",
    "test_data_predict(x,y['label_1'],x_test,pca_x,pca_x_test,\"label_1\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "73b73fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted labels before feature engineering\n",
      "Sucessfully predicted labels after feature engineering\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_3'],100)\n",
    "num_features = 15\n",
    "pca_x, pca_x_test = perform_PCA(x[selected_cols],x_test[selected_cols],num_features)\n",
    "pca_x_test.columns = ['New feature ' + str(i) for i in range(1, num_features + 1)]\n",
    "test_data_predict(x,y['label_3'],x_test,pca_x,pca_x_test,\"label_3\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eba53d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted labels before feature engineering\n",
      "Sucessfully predicted labels after feature engineering\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x,y['label_4'],100)\n",
    "num_features = 30\n",
    "pca_x, pca_x_test = perform_PCA(x[selected_cols],x_test[selected_cols],num_features)\n",
    "pca_x_test.columns = ['New feature ' + str(i) for i in range(1, num_features + 1)]\n",
    "\n",
    "test_data_predict(x,y['label_4'],x_test,pca_x,pca_x_test,\"label_4\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d885744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucessfully predicted labels before feature engineering\n",
      "Sucessfully predicted labels after feature engineering\n"
     ]
    }
   ],
   "source": [
    "selected_cols = select_cols_using_mutual_info_regression(x_label_2,y_label_2['label_2'],100)\n",
    "num_features = 40\n",
    "pca_x, pca_x_test = perform_PCA(x_label_2[selected_cols],x_test[selected_cols],num_features)\n",
    "pca_x_test.columns = ['New feature ' + str(i) for i in range(1, num_features + 1)]\n",
    "test_data_predict(x_label_2,y_label_2['label_2'],x_test,pca_x,pca_x_test,\"label_2\",num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5eae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
